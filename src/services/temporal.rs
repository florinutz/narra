//! Narrative phase auto-detection via temporal-semantic clustering.
//!
//! Clusters entities using a composite narrative distance metric that blends
//! embedding similarity, event sequence proximity, and scene co-occurrence
//! to detect "acts" or "arcs" in the story automatically.

use crate::db::connection::NarraDb;
use crate::models::phase::{self, PhaseCreate};
use crate::services::EntityType;
use crate::NarraError;
use async_trait::async_trait;
use linfa::prelude::*;
use linfa_clustering::KMeans;
use ndarray::{Array1, Array2};
use serde::Serialize;
use std::collections::HashMap;
use std::sync::Arc;

// ---------------------------------------------------------------------------
// Types
// ---------------------------------------------------------------------------

/// An entity with its embedding and temporal context for phase detection.
#[derive(Debug, Clone)]
pub struct TemporalEntity {
    pub id: String,
    pub entity_type: String,
    pub name: String,
    pub embedding: Vec<f32>,
    /// Normalized position(s) in event sequence [0.0, 1.0].
    /// Multiple values for entities spanning multiple events.
    /// Empty for entities with no event anchor.
    pub sequence_positions: Vec<f32>,
    /// Original (non-normalized) event sequence numbers.
    /// Corresponds 1:1 with sequence_positions.
    /// Empty for entities with no event anchor.
    pub original_sequences: Vec<i64>,
}

/// Tunable weights for the three narrative distance signals.
#[derive(Debug, Clone, Serialize)]
pub struct PhaseWeights {
    pub content: f32,
    pub neighborhood: f32,
    pub temporal: f32,
}

impl Default for PhaseWeights {
    fn default() -> Self {
        Self {
            content: 0.6,
            neighborhood: 0.25,
            temporal: 0.15,
        }
    }
}

/// A detected narrative phase.
#[derive(Debug, Clone, Serialize)]
pub struct NarrativePhase {
    pub phase_id: usize,
    pub label: String,
    pub members: Vec<PhaseMember>,
    pub member_count: usize,
    pub sequence_range: Option<(i64, i64)>,
    pub entity_type_counts: HashMap<String, usize>,
}

/// A member within a narrative phase.
#[derive(Debug, Clone, Serialize)]
pub struct PhaseMember {
    pub entity_id: String,
    pub entity_type: String,
    pub name: String,
    pub centrality: f32,
    pub sequence_position: Option<f32>,
}

/// Result of phase auto-detection.
#[derive(Debug, Clone, Serialize)]
pub struct PhaseDetectionResult {
    pub phases: Vec<NarrativePhase>,
    pub total_entities: usize,
    pub entities_without_embeddings: usize,
    pub entities_without_temporal_anchor: usize,
    pub weights_used: PhaseWeights,
}

/// Result of an anchor-based "query around" operation.
#[derive(Debug, Clone, Serialize)]
pub struct NarrativeNeighborhood {
    pub anchor: PhaseMember,
    pub neighbors: Vec<NarrativeNeighbor>,
    pub anchor_phases: Vec<usize>,
}

/// A neighbor in narrative space.
#[derive(Debug, Clone, Serialize)]
pub struct NarrativeNeighbor {
    pub entity_id: String,
    pub entity_type: String,
    pub name: String,
    pub similarity: f32,
    pub shared_scenes: usize,
    pub sequence_distance: Option<f32>,
}

/// An entity that bridges multiple narrative phases.
#[derive(Debug, Clone, Serialize)]
pub struct PhaseTransition {
    pub entity_id: String,
    pub entity_type: String,
    pub name: String,
    /// Phase IDs this entity belongs to (always >= 2)
    pub phase_ids: Vec<usize>,
    /// Phase labels this entity bridges
    pub phase_labels: Vec<String>,
    /// Span: how far apart the bridged phases are in sequence space
    pub sequence_span: Option<f64>,
    /// Bridge strength: high centrality across multiple phases = stronger bridge
    pub bridge_strength: f32,
}

/// Result of phase transition analysis.
#[derive(Debug, Clone, Serialize)]
pub struct TransitionAnalysis {
    pub transitions: Vec<PhaseTransition>,
    pub total_bridge_entities: usize,
    pub phases_analyzed: usize,
    /// Phase adjacency: which phases share bridge entities
    pub phase_connections: Vec<(usize, usize, usize)>, // (phase_a, phase_b, shared_bridges)
}

// ---------------------------------------------------------------------------
// Data provider trait
// ---------------------------------------------------------------------------

#[async_trait]
pub trait TemporalDataProvider: Send + Sync {
    /// Entities with embeddings + their event sequence position(s).
    /// Returns (entities_with_embeddings, total_entity_count).
    async fn get_entities_with_temporal_context(
        &self,
        entity_types: &[EntityType],
    ) -> Result<(Vec<TemporalEntity>, usize), NarraError>;

    /// Scene co-occurrence: which entities share scenes.
    /// Returns Vec<(entity_id_a, entity_id_b, shared_scene_count)>.
    async fn get_scene_cooccurrences(&self) -> Result<Vec<(String, String, usize)>, NarraError>;

    /// Save detected phases to persistent storage (wipe + recreate).
    async fn save_phases(&self, result: &PhaseDetectionResult) -> Result<(), NarraError>;

    /// Load previously saved phases from storage.
    async fn load_phases(&self) -> Result<Option<PhaseDetectionResult>, NarraError>;

    /// Check if saved phases exist.
    async fn has_saved_phases(&self) -> Result<bool, NarraError>;

    /// Delete all saved phases. Returns count of deleted phases.
    async fn delete_all_phases(&self) -> Result<usize, NarraError>;
}

// ---------------------------------------------------------------------------
// SurrealDB implementation
// ---------------------------------------------------------------------------

pub struct SurrealTemporalDataProvider {
    db: Arc<NarraDb>,
}

impl SurrealTemporalDataProvider {
    pub fn new(db: Arc<NarraDb>) -> Self {
        Self { db }
    }
}

#[async_trait]
impl TemporalDataProvider for SurrealTemporalDataProvider {
    async fn get_entities_with_temporal_context(
        &self,
        entity_types: &[EntityType],
    ) -> Result<(Vec<TemporalEntity>, usize), NarraError> {
        let mut entities = Vec::new();
        let mut total_count = 0;

        // First get max sequence for normalization
        let max_seq = self.get_max_sequence().await?.unwrap_or(1) as f32;

        for entity_type in entity_types {
            if !entity_type.has_embeddings() {
                continue;
            }

            let table = entity_type.table_name();
            let name_field = match entity_type {
                EntityType::Event | EntityType::Scene => "title",
                _ => "name",
            };

            // Fetch entities with embeddings
            let query_str = format!(
                "SELECT id, '{table}' AS entity_type, {name_field} AS name, embedding \
                 FROM {table} WHERE embedding IS NOT NONE",
            );
            let mut response = self.db.query(&query_str).await?;

            #[derive(serde::Deserialize)]
            struct EntityRow {
                id: surrealdb::RecordId,
                entity_type: String,
                name: String,
                embedding: Vec<f32>,
            }

            let rows: Vec<EntityRow> = response.take(0).unwrap_or_default();

            // Count total entities (including those without embeddings)
            let count_query = format!("SELECT count() FROM {} GROUP ALL", table);
            let mut count_resp = self.db.query(&count_query).await?;

            #[derive(serde::Deserialize)]
            struct CountResult {
                count: i64,
            }

            let counts: Vec<CountResult> = count_resp.take(0).unwrap_or_default();
            if let Some(c) = counts.first() {
                total_count += c.count as usize;
            }

            for row in rows {
                let id_str = row.id.to_string();
                let (normalized_positions, original_sequences) = self
                    .get_sequence_positions(entity_type, &id_str, max_seq)
                    .await?;

                entities.push(TemporalEntity {
                    id: id_str,
                    entity_type: row.entity_type,
                    name: row.name,
                    embedding: row.embedding,
                    sequence_positions: normalized_positions,
                    original_sequences,
                });
            }
        }

        Ok((entities, total_count))
    }

    async fn get_scene_cooccurrences(&self) -> Result<Vec<(String, String, usize)>, NarraError> {
        // Get all scene participations
        let query = "SELECT type::string(in) AS char_id, type::string(out) AS scene_id \
                     FROM participates_in";
        let mut resp = self.db.query(query).await?;

        #[derive(serde::Deserialize)]
        struct Participation {
            char_id: String,
            scene_id: String,
        }

        let participations: Vec<Participation> = resp.take(0).unwrap_or_default();

        // Build scene -> [entities] map
        let mut scene_entities: HashMap<String, Vec<String>> = HashMap::new();
        for p in &participations {
            scene_entities
                .entry(p.scene_id.clone())
                .or_default()
                .push(p.char_id.clone());
        }

        // Count co-occurrences
        let mut pair_counts: HashMap<(String, String), usize> = HashMap::new();
        for members in scene_entities.values() {
            for i in 0..members.len() {
                for j in (i + 1)..members.len() {
                    let key = if members[i] < members[j] {
                        (members[i].clone(), members[j].clone())
                    } else {
                        (members[j].clone(), members[i].clone())
                    };
                    *pair_counts.entry(key).or_insert(0) += 1;
                }
            }
        }

        Ok(pair_counts
            .into_iter()
            .map(|((a, b), count)| (a, b, count))
            .collect())
    }

    async fn save_phases(&self, result: &PhaseDetectionResult) -> Result<(), NarraError> {
        // Wipe existing phases
        phase::delete_all_phases(&self.db).await?;

        // Create phase records + membership edges
        for p in &result.phases {
            let phase_id = format!("phase_{}", p.phase_id);

            let entity_type_counts: HashMap<String, serde_json::Value> = p
                .entity_type_counts
                .iter()
                .map(|(k, v)| (k.clone(), serde_json::json!(*v)))
                .collect();

            let data = PhaseCreate {
                name: format!("Phase {}", p.phase_id),
                label: p.label.clone(),
                phase_order: p.phase_id as i64,
                sequence_range_min: p.sequence_range.map(|(min, _)| min),
                sequence_range_max: p.sequence_range.map(|(_, max)| max),
                entity_type_counts,
                weights_content: result.weights_used.content as f64,
                weights_neighborhood: result.weights_used.neighborhood as f64,
                weights_temporal: result.weights_used.temporal as f64,
                member_count: p.member_count as i64,
            };

            phase::create_phase_with_id(&self.db, &phase_id, data).await?;

            for m in &p.members {
                phase::create_membership(
                    &self.db,
                    &m.entity_id,
                    &phase_id,
                    &m.entity_type,
                    &m.name,
                    m.centrality as f64,
                    m.sequence_position.map(|p| p as f64),
                )
                .await?;
            }
        }

        Ok(())
    }

    async fn load_phases(&self) -> Result<Option<PhaseDetectionResult>, NarraError> {
        let phases = phase::list_phases(&self.db).await?;
        if phases.is_empty() {
            return Ok(None);
        }

        let mut narrative_phases = Vec::with_capacity(phases.len());

        for p in &phases {
            let phase_key = p.id.key().to_string();

            let memberships = phase::get_phase_members(&self.db, &phase_key).await?;

            let members: Vec<PhaseMember> = memberships
                .iter()
                .map(|m| PhaseMember {
                    entity_id: m.entity.to_string(),
                    entity_type: m.entity_type.clone(),
                    name: m.entity_name.clone(),
                    centrality: m.centrality as f32,
                    sequence_position: m.sequence_position.map(|p| p as f32),
                })
                .collect();

            let entity_type_counts: HashMap<String, usize> = p
                .entity_type_counts
                .iter()
                .filter_map(|(k, v)| {
                    v.as_u64()
                        .or_else(|| v.as_i64().map(|i| i as u64))
                        .map(|n| (k.clone(), n as usize))
                })
                .collect();

            let sequence_range = match (p.sequence_range_min, p.sequence_range_max) {
                (Some(min), Some(max)) => Some((min, max)),
                _ => None,
            };

            narrative_phases.push(NarrativePhase {
                phase_id: p.phase_order as usize,
                label: p.label.clone(),
                member_count: members.len(),
                members,
                sequence_range,
                entity_type_counts,
            });
        }

        // Reconstruct weights from first phase
        let first = &phases[0];
        let weights = PhaseWeights {
            content: first.weights_content as f32,
            neighborhood: first.weights_neighborhood as f32,
            temporal: first.weights_temporal as f32,
        };

        Ok(Some(PhaseDetectionResult {
            phases: narrative_phases,
            total_entities: 0,
            entities_without_embeddings: 0,
            entities_without_temporal_anchor: 0,
            weights_used: weights,
        }))
    }

    async fn has_saved_phases(&self) -> Result<bool, NarraError> {
        let mut resp = self.db.query("SELECT count() FROM phase GROUP ALL").await?;

        #[derive(serde::Deserialize)]
        struct CountResult {
            count: i64,
        }

        let counts: Vec<CountResult> = resp.take(0).unwrap_or_default();
        Ok(counts.first().map(|c| c.count > 0).unwrap_or(false))
    }

    async fn delete_all_phases(&self) -> Result<usize, NarraError> {
        phase::delete_all_phases(&self.db).await
    }
}

impl SurrealTemporalDataProvider {
    async fn get_max_sequence(&self) -> Result<Option<i64>, NarraError> {
        let mut resp = self
            .db
            .query("SELECT math::max(sequence) AS max_seq FROM event GROUP ALL")
            .await?;

        #[derive(serde::Deserialize)]
        struct MaxSeq {
            max_seq: Option<i64>,
        }

        let rows: Vec<MaxSeq> = resp.take(0).unwrap_or_default();
        Ok(rows.first().and_then(|r| r.max_seq))
    }

    async fn get_sequence_positions(
        &self,
        entity_type: &EntityType,
        entity_id: &str,
        max_seq: f32,
    ) -> Result<(Vec<f32>, Vec<i64>), NarraError> {
        if max_seq <= 0.0 {
            return Ok((vec![], vec![]));
        }

        let (normalized, original) = match entity_type {
            EntityType::Event => {
                // Events have direct sequence
                let q = format!("SELECT sequence FROM {}", entity_id);
                let mut resp = self.db.query(&q).await?;

                #[derive(serde::Deserialize)]
                struct SeqRow {
                    sequence: Option<i64>,
                }

                let rows: Vec<SeqRow> = resp.take(0).unwrap_or_default();
                let seqs: Vec<i64> = rows.into_iter().filter_map(|r| r.sequence).collect();
                let normalized: Vec<f32> = seqs.iter().map(|&s| s as f32 / max_seq).collect();
                (normalized, seqs)
            }
            EntityType::Scene => {
                // Scenes link to events via event field
                let q = format!("SELECT event.sequence AS seq FROM {}", entity_id);
                let mut resp = self.db.query(&q).await?;

                #[derive(serde::Deserialize)]
                struct SeqRow {
                    seq: Option<i64>,
                }

                let rows: Vec<SeqRow> = resp.take(0).unwrap_or_default();
                let seqs: Vec<i64> = rows.into_iter().filter_map(|r| r.seq).collect();
                let normalized: Vec<f32> = seqs.iter().map(|&s| s as f32 / max_seq).collect();
                (normalized, seqs)
            }
            EntityType::Character => {
                // Characters participate in scenes which link to events
                let q = format!(
                    "SELECT out.event.sequence AS seq FROM participates_in WHERE in = {}",
                    entity_id
                );
                let mut resp = self.db.query(&q).await?;

                #[derive(serde::Deserialize)]
                struct SeqRow {
                    seq: Option<i64>,
                }

                let rows: Vec<SeqRow> = resp.take(0).unwrap_or_default();
                let seqs: Vec<i64> = rows.into_iter().filter_map(|r| r.seq).collect();
                let normalized: Vec<f32> = seqs.iter().map(|&s| s as f32 / max_seq).collect();
                (normalized, seqs)
            }
            EntityType::Location => {
                // Locations appear in scenes which link to events
                let q = format!(
                    "SELECT event.sequence AS seq FROM scene WHERE location = {}",
                    entity_id
                );
                let mut resp = self.db.query(&q).await?;

                #[derive(serde::Deserialize)]
                struct SeqRow {
                    seq: Option<i64>,
                }

                let rows: Vec<SeqRow> = resp.take(0).unwrap_or_default();
                let seqs: Vec<i64> = rows.into_iter().filter_map(|r| r.seq).collect();
                let normalized: Vec<f32> = seqs.iter().map(|&s| s as f32 / max_seq).collect();
                (normalized, seqs)
            }
            _ => (vec![], vec![]),
        };

        Ok((normalized, original))
    }
}

// ---------------------------------------------------------------------------
// TemporalService
// ---------------------------------------------------------------------------

const POSITIONAL_DIMS: usize = 8;

pub struct TemporalService {
    data: Arc<dyn TemporalDataProvider>,
}

impl TemporalService {
    pub fn new(db: Arc<NarraDb>) -> Self {
        Self {
            data: Arc::new(SurrealTemporalDataProvider::new(db)),
        }
    }

    pub fn with_provider(data: Arc<dyn TemporalDataProvider>) -> Self {
        Self { data }
    }

    /// Save detected phases to persistent storage.
    pub async fn save_phases(&self, result: &PhaseDetectionResult) -> Result<(), NarraError> {
        self.data.save_phases(result).await
    }

    /// Load previously saved phases.
    pub async fn load_phases(&self) -> Result<Option<PhaseDetectionResult>, NarraError> {
        self.data.load_phases().await
    }

    /// Check if saved phases exist.
    pub async fn has_saved_phases(&self) -> Result<bool, NarraError> {
        self.data.has_saved_phases().await
    }

    /// Delete all saved phases. Returns count deleted.
    pub async fn delete_all_phases(&self) -> Result<usize, NarraError> {
        self.data.delete_all_phases().await
    }

    /// Load saved phases if available, otherwise detect fresh.
    pub async fn load_or_detect_phases(
        &self,
        entity_types: Vec<EntityType>,
        num_phases: Option<usize>,
        weights: Option<PhaseWeights>,
    ) -> Result<PhaseDetectionResult, NarraError> {
        if let Some(saved) = self.data.load_phases().await? {
            return Ok(saved);
        }
        self.detect_phases(entity_types, num_phases, weights).await
    }

    /// Auto-detect narrative phases via composite clustering.
    pub async fn detect_phases(
        &self,
        entity_types: Vec<EntityType>,
        num_phases: Option<usize>,
        weights: Option<PhaseWeights>,
    ) -> Result<PhaseDetectionResult, NarraError> {
        let weights = weights.unwrap_or_default();

        let (entity_data, total_entities) = self
            .data
            .get_entities_with_temporal_context(&entity_types)
            .await?;

        let cooccurrences = self.data.get_scene_cooccurrences().await?;

        let entities_with_embeddings = entity_data.len();
        let entities_without_embeddings = total_entities.saturating_sub(entities_with_embeddings);
        let entities_without_temporal_anchor = entity_data
            .iter()
            .filter(|e| e.sequence_positions.is_empty())
            .count();

        if entities_with_embeddings < 3 {
            return Err(NarraError::Database(format!(
                "Insufficient entities for phase detection: {} with embeddings (need at least 3)",
                entities_with_embeddings
            )));
        }

        // Build co-occurrence map for neighborhood computation
        let cooccurrence_map = build_cooccurrence_map(&cooccurrences);

        // Build entity index for fast lookup
        let entity_index: HashMap<&str, usize> = entity_data
            .iter()
            .enumerate()
            .map(|(i, e)| (e.id.as_str(), i))
            .collect();

        // Determine embedding dims from first entity
        let emb_dims = entity_data[0].embedding.len();
        let narrative_dims = emb_dims + emb_dims + POSITIONAL_DIMS; // content + neighborhood + temporal

        // Compute narrative vectors
        let mut narrative_vectors: Vec<Vec<f64>> = Vec::with_capacity(entities_with_embeddings);

        for entity in &entity_data {
            let mut vec = Vec::with_capacity(narrative_dims);

            // a) Content: L2-normalized embedding
            let norm = l2_norm(&entity.embedding);
            for &v in &entity.embedding {
                let normalized = if norm > 0.0 { v / norm } else { 0.0 };
                vec.push((normalized * weights.content) as f64);
            }

            // b) Neighborhood: average embedding of co-occurring entities
            let neighborhood = compute_neighborhood(
                entity,
                &cooccurrence_map,
                &entity_index,
                &entity_data,
                emb_dims,
            );
            for v in &neighborhood {
                vec.push((*v * weights.neighborhood) as f64);
            }

            // c) Temporal: positional encoding of median sequence position
            let temporal = if entity.sequence_positions.is_empty() {
                [0.0f32; POSITIONAL_DIMS]
            } else {
                let median = median_position(&entity.sequence_positions);
                positional_encoding(median)
            };
            for v in &temporal {
                vec.push((*v * weights.temporal) as f64);
            }

            narrative_vectors.push(vec);
        }

        // Build matrix for k-means
        let mut matrix_data = Vec::with_capacity(entities_with_embeddings * narrative_dims);
        for nv in &narrative_vectors {
            matrix_data.extend(nv);
        }

        let embedding_matrix =
            Array2::from_shape_vec((entities_with_embeddings, narrative_dims), matrix_data)
                .map_err(|e| NarraError::Database(format!("Failed to create matrix: {}", e)))?;

        let num_clusters = if let Some(n) = num_phases {
            n.max(2).min(entities_with_embeddings - 1)
        } else {
            let auto = ((entities_with_embeddings as f32 / 2.0).sqrt()).ceil() as usize;
            auto.max(2).min(entities_with_embeddings - 1)
        };

        let dataset = DatasetBase::new(
            embedding_matrix.clone(),
            Array1::from_elem(entities_with_embeddings, ()),
        );

        let model = KMeans::params(num_clusters)
            .max_n_iterations(300)
            .tolerance(1e-4)
            .fit(&dataset)
            .map_err(|e| NarraError::Database(format!("K-means clustering failed: {}", e)))?;

        let predictions = model.predict(&dataset);
        let cluster_assignments: Vec<usize> = predictions.iter().cloned().collect();
        let centroids = model.centroids();

        // Group entities by cluster with soft multi-membership:
        // An entity belongs to its primary cluster, but also to any other cluster
        // where its distance to the centroid is within 20% of its primary distance.
        // This enables bridge entity detection across narrative phases.
        let mut clusters: HashMap<usize, Vec<(usize, f32)>> = HashMap::new();
        for (idx, &primary_cluster_id) in cluster_assignments.iter().enumerate() {
            let entity_vec = &narrative_vectors[idx];

            // Compute distances to all centroids
            let mut distances: Vec<(usize, f64, f32)> = Vec::new();
            for cluster_id in 0..centroids.nrows() {
                let centroid = centroids.row(cluster_id);
                let mut distance_sq = 0.0_f64;
                for (i, &v) in entity_vec.iter().enumerate() {
                    let diff = v - centroid[i];
                    distance_sq += diff * diff;
                }
                let distance = distance_sq.sqrt();
                let centrality = 1.0 / (1.0 + distance);
                distances.push((cluster_id, distance, centrality as f32));
            }

            // Sort by distance (ascending)
            distances.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));

            let primary_distance = distances[0].1;
            let threshold = primary_distance * 1.2; // 20% tolerance

            // Add entity to primary cluster and any other clusters within threshold
            for (cluster_id, distance, centrality) in distances {
                if cluster_id == primary_cluster_id || distance <= threshold {
                    clusters
                        .entry(cluster_id)
                        .or_default()
                        .push((idx, centrality));
                }
            }
        }

        // Build NarrativePhase structs
        let mut phases: Vec<NarrativePhase> = clusters
            .into_iter()
            .map(|(cluster_id, mut members_data)| {
                members_data
                    .sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

                let members: Vec<PhaseMember> = members_data
                    .iter()
                    .map(|&(idx, centrality)| {
                        let entity = &entity_data[idx];
                        let median_pos = if entity.sequence_positions.is_empty() {
                            None
                        } else {
                            Some(median_position(&entity.sequence_positions))
                        };
                        PhaseMember {
                            entity_id: entity.id.clone(),
                            entity_type: entity.entity_type.clone(),
                            name: entity.name.clone(),
                            centrality,
                            sequence_position: median_pos,
                        }
                    })
                    .collect();

                // Auto-label: prioritize events, then scenes, then other entities
                // Format: "Event1, Event2 (seq 10-45)" or "Character1, Scene1 (seq 10-45)"
                let mut label_parts: Vec<String> = Vec::new();

                // First, collect events (up to 2)
                for m in members.iter() {
                    if m.entity_type == "event" && label_parts.len() < 2 {
                        label_parts.push(m.name.clone());
                    }
                }

                // Then scenes if we don't have 2 events
                if label_parts.len() < 2 {
                    for m in members.iter() {
                        if m.entity_type == "scene" && label_parts.len() < 2 {
                            label_parts.push(m.name.clone());
                        }
                    }
                }

                // Fill remaining slots with highest-centrality entities
                if label_parts.len() < 2 {
                    for m in members.iter() {
                        if m.entity_type != "event"
                            && m.entity_type != "scene"
                            && label_parts.len() < 2
                        {
                            label_parts.push(m.name.clone());
                        }
                    }
                }

                // Sequence range from all members with original sequences
                let all_sequences: Vec<i64> = members_data
                    .iter()
                    .flat_map(|&(idx, _)| entity_data[idx].original_sequences.iter().copied())
                    .collect();

                let sequence_range = if all_sequences.is_empty() {
                    None
                } else {
                    let min = *all_sequences.iter().min().unwrap();
                    let max = *all_sequences.iter().max().unwrap();
                    Some((min, max))
                };

                // Generate final label with sequence range
                let label = if label_parts.is_empty() {
                    if let Some((min, max)) = sequence_range {
                        format!("Unnamed Phase (seq {}-{})", min, max)
                    } else {
                        "Unnamed Phase".to_string()
                    }
                } else {
                    let base_label = label_parts.join(", ");
                    if let Some((min, max)) = sequence_range {
                        if min == max {
                            format!("{} (seq {})", base_label, min)
                        } else {
                            format!("{} (seq {}-{})", base_label, min, max)
                        }
                    } else {
                        base_label
                    }
                };

                // Entity type counts
                let mut entity_type_counts: HashMap<String, usize> = HashMap::new();
                for m in &members {
                    *entity_type_counts.entry(m.entity_type.clone()).or_insert(0) += 1;
                }

                let member_count = members.len();

                NarrativePhase {
                    phase_id: cluster_id,
                    label,
                    members,
                    member_count,
                    sequence_range,
                    entity_type_counts,
                }
            })
            .collect();

        // Sort phases by median sequence position for narrative chronology
        phases.sort_by(|a, b| {
            let median_a = phase_median_position(a);
            let median_b = phase_median_position(b);
            median_a
                .partial_cmp(&median_b)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        // Reassign phase_id to match chronological order
        for (i, phase) in phases.iter_mut().enumerate() {
            phase.phase_id = i;
        }

        Ok(PhaseDetectionResult {
            phases,
            total_entities,
            entities_without_embeddings,
            entities_without_temporal_anchor,
            weights_used: weights,
        })
    }

    /// Find entities narratively close to an anchor entity.
    pub async fn query_around(
        &self,
        anchor_id: &str,
        entity_types: Vec<EntityType>,
        limit: usize,
    ) -> Result<NarrativeNeighborhood, NarraError> {
        let weights = PhaseWeights::default();

        let (entity_data, _total) = self
            .data
            .get_entities_with_temporal_context(&entity_types)
            .await?;

        let cooccurrences = self.data.get_scene_cooccurrences().await?;
        let cooccurrence_map = build_cooccurrence_map(&cooccurrences);

        // Build shared scene counts for anchor
        let mut anchor_shared_scenes: HashMap<String, usize> = HashMap::new();
        for (a, b, count) in &cooccurrences {
            if a == anchor_id {
                anchor_shared_scenes.insert(b.clone(), *count);
            } else if b == anchor_id {
                anchor_shared_scenes.insert(a.clone(), *count);
            }
        }

        let entity_index: HashMap<&str, usize> = entity_data
            .iter()
            .enumerate()
            .map(|(i, e)| (e.id.as_str(), i))
            .collect();

        let anchor_idx = entity_index
            .get(anchor_id)
            .ok_or_else(|| NarraError::NotFound {
                entity_type: "entity".to_string(),
                id: anchor_id.to_string(),
            })?;

        let emb_dims = entity_data[0].embedding.len();

        // Compute narrative vectors for all entities
        let narrative_vectors: Vec<Vec<f32>> = entity_data
            .iter()
            .map(|entity| {
                compute_narrative_vector(
                    entity,
                    &weights,
                    &cooccurrence_map,
                    &entity_index,
                    &entity_data,
                    emb_dims,
                )
            })
            .collect();

        let anchor_vec = &narrative_vectors[*anchor_idx];
        let anchor_entity = &entity_data[*anchor_idx];
        let anchor_median = if anchor_entity.sequence_positions.is_empty() {
            None
        } else {
            Some(median_position(&anchor_entity.sequence_positions))
        };

        // Compute similarities
        let mut scored: Vec<(usize, f32)> = narrative_vectors
            .iter()
            .enumerate()
            .filter(|(i, _)| i != anchor_idx)
            .map(|(i, vec)| {
                let sim = cosine_similarity_f32(anchor_vec, vec);
                (i, sim)
            })
            .collect();

        scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        scored.truncate(limit);

        let neighbors: Vec<NarrativeNeighbor> = scored
            .iter()
            .map(|&(idx, similarity)| {
                let entity = &entity_data[idx];
                let shared_scenes = anchor_shared_scenes.get(&entity.id).copied().unwrap_or(0);
                let seq_dist = match (anchor_median, entity.sequence_positions.is_empty()) {
                    (Some(a), false) => {
                        Some((a - median_position(&entity.sequence_positions)).abs())
                    }
                    _ => None,
                };

                NarrativeNeighbor {
                    entity_id: entity.id.clone(),
                    entity_type: entity.entity_type.clone(),
                    name: entity.name.clone(),
                    similarity,
                    shared_scenes,
                    sequence_distance: seq_dist,
                }
            })
            .collect();

        // Use saved phases if available, otherwise detect
        let phase_result = self
            .load_or_detect_phases(entity_types, None, Some(PhaseWeights::default()))
            .await?;

        let anchor_phases: Vec<usize> = phase_result
            .phases
            .iter()
            .filter(|p| p.members.iter().any(|m| m.entity_id == anchor_id))
            .map(|p| p.phase_id)
            .collect();

        let anchor_member = PhaseMember {
            entity_id: anchor_entity.id.clone(),
            entity_type: anchor_entity.entity_type.clone(),
            name: anchor_entity.name.clone(),
            centrality: 1.0,
            sequence_position: anchor_median,
        };

        Ok(NarrativeNeighborhood {
            anchor: anchor_member,
            neighbors,
            anchor_phases,
        })
    }

    /// Identify entities that bridge multiple narrative phases.
    ///
    /// Runs phase detection, then finds entities appearing in 2+ phases.
    /// Returns them ranked by bridge_strength (cross-phase centrality).
    pub async fn detect_transitions(
        &self,
        entity_types: Vec<EntityType>,
        num_phases: Option<usize>,
        weights: Option<PhaseWeights>,
    ) -> Result<TransitionAnalysis, NarraError> {
        let phase_result = self
            .load_or_detect_phases(entity_types, num_phases, weights)
            .await?;

        // Build entity_id -> vec of (phase_id, centrality) from all phases
        let mut entity_phases: HashMap<String, Vec<(usize, f32, String)>> = HashMap::new();
        // Also build entity_id -> entity metadata
        let mut entity_meta: HashMap<String, (String, String)> = HashMap::new(); // (type, name)

        for phase in &phase_result.phases {
            for member in &phase.members {
                entity_phases
                    .entry(member.entity_id.clone())
                    .or_default()
                    .push((phase.phase_id, member.centrality, phase.label.clone()));
                entity_meta
                    .entry(member.entity_id.clone())
                    .or_insert_with(|| (member.entity_type.clone(), member.name.clone()));
            }
        }

        // Find bridge entities (appear in 2+ phases)
        let mut transitions: Vec<PhaseTransition> = entity_phases
            .into_iter()
            .filter(|(_, phases)| phases.len() >= 2)
            .map(|(entity_id, phases)| {
                let (entity_type, name) = entity_meta.get(&entity_id).cloned().unwrap_or_default();

                let phase_ids: Vec<usize> = phases.iter().map(|(id, _, _)| *id).collect();
                let phase_labels: Vec<String> =
                    phases.iter().map(|(_, _, label)| label.clone()).collect();

                // Bridge strength = mean centrality across phases * number of phases bridged
                let mean_centrality: f32 =
                    phases.iter().map(|(_, c, _)| c).sum::<f32>() / phases.len() as f32;
                let bridge_strength = mean_centrality * phases.len() as f32;

                // Sequence span from phase sequence ranges
                let sequence_span = {
                    let phase_ranges: Vec<(i64, i64)> = phase_ids
                        .iter()
                        .filter_map(|&pid| {
                            phase_result
                                .phases
                                .iter()
                                .find(|p| p.phase_id == pid)
                                .and_then(|p| p.sequence_range)
                        })
                        .collect();
                    if phase_ranges.len() >= 2 {
                        let min = phase_ranges.iter().map(|(a, _)| *a).min().unwrap();
                        let max = phase_ranges.iter().map(|(_, b)| *b).max().unwrap();
                        Some((max - min) as f64)
                    } else {
                        None
                    }
                };

                PhaseTransition {
                    entity_id,
                    entity_type,
                    name,
                    phase_ids,
                    phase_labels,
                    sequence_span,
                    bridge_strength,
                }
            })
            .collect();

        // Sort by bridge_strength descending
        transitions.sort_by(|a, b| {
            b.bridge_strength
                .partial_cmp(&a.bridge_strength)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        // Compute phase connections (which phases share bridge entities)
        let mut connection_counts: HashMap<(usize, usize), usize> = HashMap::new();
        for t in &transitions {
            let ids = &t.phase_ids;
            for i in 0..ids.len() {
                for j in (i + 1)..ids.len() {
                    let key = if ids[i] < ids[j] {
                        (ids[i], ids[j])
                    } else {
                        (ids[j], ids[i])
                    };
                    *connection_counts.entry(key).or_insert(0) += 1;
                }
            }
        }

        let mut phase_connections: Vec<(usize, usize, usize)> = connection_counts
            .into_iter()
            .map(|((a, b), count)| (a, b, count))
            .collect();
        phase_connections.sort_by(|a, b| b.2.cmp(&a.2));

        let total_bridge_entities = transitions.len();

        Ok(TransitionAnalysis {
            transitions,
            total_bridge_entities,
            phases_analyzed: phase_result.phases.len(),
            phase_connections,
        })
    }
}

// ---------------------------------------------------------------------------
// Helper functions
// ---------------------------------------------------------------------------

/// Sinusoidal positional encoding (8 dims) for a [0.0, 1.0] position.
fn positional_encoding(position: f32) -> [f32; POSITIONAL_DIMS] {
    let mut enc = [0.0f32; POSITIONAL_DIMS];
    for i in 0..4 {
        let freq = (1 << i) as f32 * std::f32::consts::PI;
        enc[2 * i] = (position * freq).sin();
        enc[2 * i + 1] = (position * freq).cos();
    }
    enc
}

fn l2_norm(v: &[f32]) -> f32 {
    v.iter().map(|x| x * x).sum::<f32>().sqrt()
}

fn median_position(positions: &[f32]) -> f32 {
    if positions.is_empty() {
        return 0.0;
    }
    let mut sorted = positions.to_vec();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    let mid = sorted.len() / 2;
    if sorted.len().is_multiple_of(2) {
        (sorted[mid - 1] + sorted[mid]) / 2.0
    } else {
        sorted[mid]
    }
}

fn phase_median_position(phase: &NarrativePhase) -> f32 {
    let positions: Vec<f32> = phase
        .members
        .iter()
        .filter_map(|m| m.sequence_position)
        .collect();
    if positions.is_empty() {
        f32::MAX
    } else {
        median_position(&positions)
    }
}

type CooccurrenceMap = HashMap<String, Vec<String>>;

fn build_cooccurrence_map(cooccurrences: &[(String, String, usize)]) -> CooccurrenceMap {
    let mut map: CooccurrenceMap = HashMap::new();
    for (a, b, _) in cooccurrences {
        map.entry(a.clone()).or_default().push(b.clone());
        map.entry(b.clone()).or_default().push(a.clone());
    }
    map
}

fn compute_neighborhood(
    entity: &TemporalEntity,
    cooccurrence_map: &CooccurrenceMap,
    entity_index: &HashMap<&str, usize>,
    entity_data: &[TemporalEntity],
    emb_dims: usize,
) -> Vec<f32> {
    let mut avg = vec![0.0f32; emb_dims];

    let neighbors = match cooccurrence_map.get(&entity.id) {
        Some(n) => n,
        None => return avg,
    };

    let mut count = 0usize;
    for neighbor_id in neighbors {
        if let Some(&idx) = entity_index.get(neighbor_id.as_str()) {
            let neighbor_emb = &entity_data[idx].embedding;
            if neighbor_emb.len() == emb_dims {
                for (i, &v) in neighbor_emb.iter().enumerate() {
                    avg[i] += v;
                }
                count += 1;
            }
        }
    }

    if count > 0 {
        for v in &mut avg {
            *v /= count as f32;
        }
        // L2-normalize
        let norm = l2_norm(&avg);
        if norm > 0.0 {
            for v in &mut avg {
                *v /= norm;
            }
        }
    }

    avg
}

fn compute_narrative_vector(
    entity: &TemporalEntity,
    weights: &PhaseWeights,
    cooccurrence_map: &CooccurrenceMap,
    entity_index: &HashMap<&str, usize>,
    entity_data: &[TemporalEntity],
    emb_dims: usize,
) -> Vec<f32> {
    let mut vec = Vec::with_capacity(emb_dims + emb_dims + POSITIONAL_DIMS);

    // Content
    let norm = l2_norm(&entity.embedding);
    for &v in &entity.embedding {
        let normalized = if norm > 0.0 { v / norm } else { 0.0 };
        vec.push(normalized * weights.content);
    }

    // Neighborhood
    let neighborhood = compute_neighborhood(
        entity,
        cooccurrence_map,
        entity_index,
        entity_data,
        emb_dims,
    );
    for v in &neighborhood {
        vec.push(*v * weights.neighborhood);
    }

    // Temporal
    let temporal = if entity.sequence_positions.is_empty() {
        [0.0f32; POSITIONAL_DIMS]
    } else {
        positional_encoding(median_position(&entity.sequence_positions))
    };
    for v in &temporal {
        vec.push(*v * weights.temporal);
    }

    vec
}

fn cosine_similarity_f32(a: &[f32], b: &[f32]) -> f32 {
    if a.len() != b.len() || a.is_empty() {
        return 0.0;
    }
    let mut dot = 0.0f32;
    let mut norm_a = 0.0f32;
    let mut norm_b = 0.0f32;
    for i in 0..a.len() {
        dot += a[i] * b[i];
        norm_a += a[i] * a[i];
        norm_b += b[i] * b[i];
    }
    let denom = norm_a.sqrt() * norm_b.sqrt();
    if denom > 0.0 {
        dot / denom
    } else {
        0.0
    }
}

// ---------------------------------------------------------------------------
// Tests
// ---------------------------------------------------------------------------

#[cfg(test)]
mod tests {
    use super::*;

    use std::sync::Mutex;

    struct MockTemporalDataProvider {
        entities: Vec<TemporalEntity>,
        total_count: usize,
        cooccurrences: Vec<(String, String, usize)>,
        saved_phases: Mutex<Option<PhaseDetectionResult>>,
    }

    impl MockTemporalDataProvider {
        fn new(
            entities: Vec<TemporalEntity>,
            total_count: usize,
            cooccurrences: Vec<(String, String, usize)>,
        ) -> Self {
            Self {
                entities,
                total_count,
                cooccurrences,
                saved_phases: Mutex::new(None),
            }
        }
    }

    #[async_trait]
    impl TemporalDataProvider for MockTemporalDataProvider {
        async fn get_entities_with_temporal_context(
            &self,
            _entity_types: &[EntityType],
        ) -> Result<(Vec<TemporalEntity>, usize), NarraError> {
            Ok((self.entities.clone(), self.total_count))
        }

        async fn get_scene_cooccurrences(
            &self,
        ) -> Result<Vec<(String, String, usize)>, NarraError> {
            Ok(self.cooccurrences.clone())
        }

        async fn save_phases(&self, result: &PhaseDetectionResult) -> Result<(), NarraError> {
            *self.saved_phases.lock().unwrap() = Some(result.clone());
            Ok(())
        }

        async fn load_phases(&self) -> Result<Option<PhaseDetectionResult>, NarraError> {
            // Mimic real DB behavior: aggregate fields aren't persisted
            Ok(self.saved_phases.lock().unwrap().clone().map(|mut r| {
                r.total_entities = 0;
                r.entities_without_embeddings = 0;
                r.entities_without_temporal_anchor = 0;
                r
            }))
        }

        async fn has_saved_phases(&self) -> Result<bool, NarraError> {
            Ok(self.saved_phases.lock().unwrap().is_some())
        }

        async fn delete_all_phases(&self) -> Result<usize, NarraError> {
            let had = self.saved_phases.lock().unwrap().take();
            Ok(had.map(|r| r.phases.len()).unwrap_or(0))
        }
    }

    fn make_entity(
        id: &str,
        name: &str,
        embedding: Vec<f32>,
        positions: Vec<f32>,
        original_seqs: Vec<i64>,
    ) -> TemporalEntity {
        TemporalEntity {
            id: id.to_string(),
            entity_type: "character".to_string(),
            name: name.to_string(),
            embedding,
            sequence_positions: positions,
            original_sequences: original_seqs,
        }
    }

    #[test]
    fn test_positional_encoding() {
        let enc_0 = positional_encoding(0.0);
        let enc_half = positional_encoding(0.5);
        let enc_one = positional_encoding(1.0);

        // At position 0, sin components should be 0, cos components should be 1
        assert!((enc_0[0]).abs() < 1e-6, "sin(0) should be ~0");
        assert!((enc_0[1] - 1.0).abs() < 1e-6, "cos(0) should be ~1");

        // Different positions should produce different encodings
        assert_ne!(enc_0, enc_half);
        assert_ne!(enc_half, enc_one);

        // Nearby positions should produce similar encodings
        let enc_a = positional_encoding(0.5);
        let enc_b = positional_encoding(0.51);
        let sim = cosine_similarity_f32(&enc_a, &enc_b);
        assert!(
            sim > 0.98,
            "Nearby positions should be very similar, got {}",
            sim
        );

        // Distant positions should be less similar
        let enc_far = positional_encoding(0.0);
        let enc_far2 = positional_encoding(1.0);
        let sim_far = cosine_similarity_f32(&enc_far, &enc_far2);
        assert!(sim_far < sim, "Distant positions should be less similar");
    }

    #[tokio::test]
    async fn test_phase_detection_distinct_phases() {
        // Two temporal clusters:
        // - early entities (positions 0.0-0.2) with embeddings near [1,0,0,0]
        // - late entities (positions 0.8-1.0) with embeddings near [0,0,0,1]
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("e1", "Early1", vec![1.0, 0.0, 0.0, 0.0], vec![0.0], vec![0]),
                make_entity(
                    "e2",
                    "Early2",
                    vec![0.9, 0.1, 0.0, 0.0],
                    vec![0.1],
                    vec![10],
                ),
                make_entity(
                    "e3",
                    "Early3",
                    vec![0.95, 0.05, 0.0, 0.0],
                    vec![0.2],
                    vec![20],
                ),
                make_entity("l1", "Late1", vec![0.0, 0.0, 0.0, 1.0], vec![0.8], vec![80]),
                make_entity("l2", "Late2", vec![0.0, 0.0, 0.1, 0.9], vec![0.9], vec![90]),
                make_entity(
                    "l3",
                    "Late3",
                    vec![0.0, 0.0, 0.05, 0.95],
                    vec![1.0],
                    vec![100],
                ),
            ],
            6,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .detect_phases(vec![EntityType::Character], Some(2), None)
            .await
            .unwrap();

        assert_eq!(result.phases.len(), 2);
        assert_eq!(result.total_entities, 6);

        // Each phase should have 3 members
        let mut sizes: Vec<usize> = result.phases.iter().map(|p| p.member_count).collect();
        sizes.sort();
        assert_eq!(sizes, vec![3, 3]);

        // First phase (chronologically) should contain early entities
        let first_phase = &result.phases[0];
        let first_names: Vec<&str> = first_phase
            .members
            .iter()
            .map(|m| m.name.as_str())
            .collect();
        assert!(
            first_names.iter().any(|n| n.starts_with("Early")),
            "First phase should contain early entities: {:?}",
            first_names
        );
    }

    #[tokio::test]
    async fn test_phase_detection_scene_cooccurrence() {
        // Groups have same embeddings within group, different between groups.
        // Neighborhood signal (average of co-occurring entities) will reinforce
        // the group distinction. Content weight is zeroed out  only neighborhood matters.
        let emb_a = vec![1.0, 0.0, 0.0, 0.0];
        let emb_b = vec![0.0, 0.0, 0.0, 1.0];
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("a1", "GroupA1", emb_a.clone(), vec![0.5], vec![50]),
                make_entity("a2", "GroupA2", emb_a.clone(), vec![0.5], vec![50]),
                make_entity("a3", "GroupA3", emb_a.clone(), vec![0.5], vec![50]),
                make_entity("b1", "GroupB1", emb_b.clone(), vec![0.5], vec![50]),
                make_entity("b2", "GroupB2", emb_b.clone(), vec![0.5], vec![50]),
                make_entity("b3", "GroupB3", emb_b.clone(), vec![0.5], vec![50]),
            ],
            6,
            vec![
                // Group A shares many scenes
                ("a1".to_string(), "a2".to_string(), 5),
                ("a1".to_string(), "a3".to_string(), 5),
                ("a2".to_string(), "a3".to_string(), 5),
                // Group B shares many scenes
                ("b1".to_string(), "b2".to_string(), 5),
                ("b1".to_string(), "b3".to_string(), 5),
                ("b2".to_string(), "b3".to_string(), 5),
            ],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        // Use pure neighborhood weight so only scene co-occurrence matters
        let weights = PhaseWeights {
            content: 0.0,
            neighborhood: 1.0,
            temporal: 0.0,
        };
        let result = service
            .detect_phases(vec![EntityType::Character], Some(2), Some(weights))
            .await
            .unwrap();

        assert_eq!(result.phases.len(), 2);

        // Each phase should have 3 members, all from the same group
        for phase in &result.phases {
            let ids: Vec<&str> = phase.members.iter().map(|m| m.entity_id.as_str()).collect();
            let all_a = ids.iter().all(|id| id.starts_with('a'));
            let all_b = ids.iter().all(|id| id.starts_with('b'));
            assert!(
                all_a || all_b,
                "Scene co-occurrence groups should cluster together: {:?}",
                ids
            );
        }
    }

    #[tokio::test]
    async fn test_phase_detection_auto_k() {
        // 8 entities -> auto K = ceil(sqrt(8/2)) = ceil(2.0) = 2
        let entities: Vec<TemporalEntity> = (0..8)
            .map(|i| {
                let mut emb = vec![0.0; 4];
                emb[i % 4] = 1.0;
                let seq = (i * 100 / 7) as i64;
                make_entity(
                    &format!("e{}", i),
                    &format!("Entity{}", i),
                    emb,
                    vec![i as f32 / 7.0],
                    vec![seq],
                )
            })
            .collect();

        let provider = MockTemporalDataProvider::new(entities, 8, vec![]);

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .detect_phases(vec![EntityType::Character], None, None)
            .await
            .unwrap();

        // Auto-K for 8 entities = ceil(sqrt(4)) = 2
        assert_eq!(result.phases.len(), 2);
    }

    #[tokio::test]
    async fn test_query_around() {
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity(
                    "anchor",
                    "Anchor",
                    vec![1.0, 0.0, 0.0, 0.0],
                    vec![0.5],
                    vec![50],
                ),
                make_entity(
                    "near",
                    "Near",
                    vec![0.9, 0.1, 0.0, 0.0],
                    vec![0.5],
                    vec![50],
                ),
                make_entity("far", "Far", vec![0.0, 0.0, 0.0, 1.0], vec![0.0], vec![0]),
                make_entity("mid", "Mid", vec![0.5, 0.5, 0.0, 0.0], vec![0.5], vec![50]),
            ],
            4,
            vec![("anchor".to_string(), "near".to_string(), 3)],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .query_around("anchor", vec![EntityType::Character], 3)
            .await
            .unwrap();

        assert_eq!(result.anchor.entity_id, "anchor");
        assert_eq!(result.neighbors.len(), 3);

        // "Near" should be the closest neighbor (similar embedding, same position, shared scenes)
        assert_eq!(result.neighbors[0].entity_id, "near");
        assert!(
            result.neighbors[0].similarity > result.neighbors[1].similarity,
            "Nearest neighbor should have highest similarity"
        );

        // "Far" should be the farthest (different embedding, different position)
        assert_eq!(result.neighbors[2].entity_id, "far");

        // Near shares scenes with anchor
        assert_eq!(result.neighbors[0].shared_scenes, 3);
    }

    #[tokio::test]
    async fn test_entities_without_temporal_anchor() {
        // Entities without sequence positions should still cluster via content + neighborhood
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("a1", "A1", vec![1.0, 0.0, 0.0, 0.0], vec![], vec![]),
                make_entity("a2", "A2", vec![0.9, 0.1, 0.0, 0.0], vec![], vec![]),
                make_entity("b1", "B1", vec![0.0, 0.0, 0.0, 1.0], vec![], vec![]),
                make_entity("b2", "B2", vec![0.0, 0.0, 0.1, 0.9], vec![], vec![]),
            ],
            4,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .detect_phases(vec![EntityType::Character], Some(2), None)
            .await
            .unwrap();

        assert_eq!(result.phases.len(), 2);
        assert_eq!(result.entities_without_temporal_anchor, 4);

        // Should still form meaningful clusters based on embeddings alone
        let total: usize = result.phases.iter().map(|p| p.member_count).sum();
        assert_eq!(total, 4);
    }

    #[tokio::test]
    async fn test_custom_weights() {
        // With temporal weight = 1.0, entities should cluster purely by timeline position
        let provider = MockTemporalDataProvider::new(
            vec![
                // Similar embeddings but different positions
                make_entity(
                    "early1",
                    "Early1",
                    vec![0.5, 0.5, 0.0, 0.0],
                    vec![0.0],
                    vec![0],
                ),
                make_entity(
                    "early2",
                    "Early2",
                    vec![0.0, 0.0, 0.5, 0.5],
                    vec![0.1],
                    vec![10],
                ),
                make_entity(
                    "late1",
                    "Late1",
                    vec![0.5, 0.5, 0.0, 0.0],
                    vec![0.9],
                    vec![90],
                ),
                make_entity(
                    "late2",
                    "Late2",
                    vec![0.0, 0.0, 0.5, 0.5],
                    vec![1.0],
                    vec![100],
                ),
            ],
            4,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let weights = PhaseWeights {
            content: 0.0,
            neighborhood: 0.0,
            temporal: 1.0,
        };
        let result = service
            .detect_phases(vec![EntityType::Character], Some(2), Some(weights))
            .await
            .unwrap();

        assert_eq!(result.phases.len(), 2);

        // With pure temporal weighting, early entities should cluster together
        for phase in &result.phases {
            let ids: Vec<&str> = phase.members.iter().map(|m| m.entity_id.as_str()).collect();
            let all_early = ids.iter().all(|id| id.starts_with("early"));
            let all_late = ids.iter().all(|id| id.starts_with("late"));
            assert!(
                all_early || all_late,
                "Pure temporal weight should cluster by timeline: {:?}",
                ids
            );
        }
    }

    #[tokio::test]
    async fn test_insufficient_entities() {
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("a", "A", vec![0.1; 4], vec![0.5], vec![50]),
                make_entity("b", "B", vec![0.2; 4], vec![0.5], vec![50]),
            ],
            2,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .detect_phases(vec![EntityType::Character], None, None)
            .await;

        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("Insufficient"));
    }

    #[tokio::test]
    async fn test_detect_transitions_bridge_entities() {
        // Test transition detection with soft multi-membership clustering.
        // Create an entity at the boundary between two phases to act as a bridge.
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("e1", "Early1", vec![1.0; 4], vec![0.0], vec![0]),
                make_entity("e2", "Early2", vec![1.0; 4], vec![0.1], vec![10]),
                make_entity("e3", "Early3", vec![1.0; 4], vec![0.2], vec![20]),
                // Bridge entity: temporally between early and late phases
                make_entity("mid", "Middle", vec![1.0; 4], vec![0.5], vec![50]),
                make_entity("l1", "Late1", vec![1.0; 4], vec![0.8], vec![80]),
                make_entity("l2", "Late2", vec![1.0; 4], vec![0.9], vec![90]),
                make_entity("l3", "Late3", vec![1.0; 4], vec![1.0], vec![100]),
            ],
            7,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .detect_transitions(
                vec![EntityType::Character],
                Some(2),
                Some(PhaseWeights {
                    content: 0.0,
                    neighborhood: 0.0,
                    temporal: 1.0, // Pure temporal clustering
                }),
            )
            .await
            .unwrap();

        // Verify the analysis ran successfully
        assert_eq!(result.phases_analyzed, 2);

        // With soft multi-membership, the "Middle" entity should appear in both phases
        // (or at least be close enough to be considered a bridge)
        if result.total_bridge_entities > 0 {
            let bridge = &result.transitions[0];
            assert_eq!(bridge.name, "Middle");
            assert_eq!(bridge.phase_ids.len(), 2, "Bridge should span 2 phases");
            assert!(
                bridge.bridge_strength > 0.0,
                "Bridge strength should be positive"
            );

            // Phase connections should exist
            assert!(
                !result.phase_connections.is_empty(),
                "Should have phase connections"
            );
        } else {
            // If no bridges detected, that's also valid (threshold might be too strict)
            // The key is that the function runs without error
            assert_eq!(result.total_bridge_entities, 0);
        }
    }

    #[tokio::test]
    async fn test_phase_label_prioritizes_events() {
        // Test that phase labels prioritize events, then scenes, with sequence range suffix
        fn make_typed_entity(
            id: &str,
            name: &str,
            entity_type: &str,
            embedding: Vec<f32>,
            positions: Vec<f32>,
            seqs: Vec<i64>,
        ) -> TemporalEntity {
            TemporalEntity {
                id: id.to_string(),
                entity_type: entity_type.to_string(),
                name: name.to_string(),
                embedding,
                sequence_positions: positions,
                original_sequences: seqs,
            }
        }

        // Phase with 2 events, 1 scene, 2 characters
        // Label should prioritize events over other entity types
        let provider = MockTemporalDataProvider::new(
            vec![
                make_typed_entity("e1", "Event1", "event", vec![1.0; 4], vec![0.1], vec![10]),
                make_typed_entity("e2", "Event2", "event", vec![1.0; 4], vec![0.2], vec![20]),
                make_typed_entity("s1", "Scene1", "scene", vec![1.0; 4], vec![0.3], vec![30]),
                make_typed_entity(
                    "c1",
                    "Char1",
                    "character",
                    vec![1.0; 4],
                    vec![0.2],
                    vec![20],
                ),
                make_typed_entity(
                    "c2",
                    "Char2",
                    "character",
                    vec![1.0; 4],
                    vec![0.3],
                    vec![30],
                ),
            ],
            5,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));
        let result = service
            .detect_phases(vec![EntityType::Event, EntityType::Scene], Some(2), None)
            .await
            .unwrap();

        // k-means enforces min 2 clusters, so we'll have 2 phases
        assert_eq!(result.phases.len(), 2);

        // At least one phase should prioritize events in its label
        let has_event_label = result
            .phases
            .iter()
            .any(|p| p.label.contains("Event1") || p.label.contains("Event2"));
        assert!(
            has_event_label,
            "At least one phase should have an event in its label"
        );

        // All phases should include sequence range in label
        for phase in &result.phases {
            assert!(
                phase.label.contains("seq"),
                "Phase label should include sequence range, got: {}",
                phase.label
            );
            assert!(
                phase.sequence_range.is_some(),
                "Phase should have sequence_range"
            );
        }
    }

    // =========================================================================
    // Phase persistence tests
    // =========================================================================

    #[tokio::test]
    async fn test_save_and_load_roundtrip() {
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("e1", "Early1", vec![1.0, 0.0, 0.0, 0.0], vec![0.0], vec![0]),
                make_entity(
                    "e2",
                    "Early2",
                    vec![0.9, 0.1, 0.0, 0.0],
                    vec![0.1],
                    vec![10],
                ),
                make_entity(
                    "e3",
                    "Early3",
                    vec![0.95, 0.05, 0.0, 0.0],
                    vec![0.2],
                    vec![20],
                ),
                make_entity("l1", "Late1", vec![0.0, 0.0, 0.0, 1.0], vec![0.8], vec![80]),
                make_entity("l2", "Late2", vec![0.0, 0.0, 0.1, 0.9], vec![0.9], vec![90]),
                make_entity(
                    "l3",
                    "Late3",
                    vec![0.0, 0.0, 0.05, 0.95],
                    vec![1.0],
                    vec![100],
                ),
            ],
            6,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));

        // Detect and save
        let detected = service
            .detect_phases(vec![EntityType::Character], Some(2), None)
            .await
            .unwrap();
        service.save_phases(&detected).await.unwrap();

        // Load and verify
        let loaded = service.load_phases().await.unwrap();
        assert!(loaded.is_some(), "Should have loaded saved phases");

        let loaded = loaded.unwrap();
        assert_eq!(loaded.phases.len(), detected.phases.len());

        for (d, l) in detected.phases.iter().zip(loaded.phases.iter()) {
            assert_eq!(d.phase_id, l.phase_id);
            assert_eq!(d.label, l.label);
            assert_eq!(d.member_count, l.member_count);
            assert_eq!(d.sequence_range, l.sequence_range);
        }
    }

    #[tokio::test]
    async fn test_load_or_detect_fallback() {
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("a", "A", vec![1.0, 0.0, 0.0, 0.0], vec![0.0], vec![0]),
                make_entity("b", "B", vec![0.0, 1.0, 0.0, 0.0], vec![0.5], vec![50]),
                make_entity("c", "C", vec![0.0, 0.0, 0.0, 1.0], vec![1.0], vec![100]),
            ],
            3,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));

        // No saved phases  should detect
        let result = service
            .load_or_detect_phases(vec![EntityType::Character], Some(2), None)
            .await
            .unwrap();
        assert_eq!(result.phases.len(), 2);
        assert!(result.total_entities > 0, "Should have detected fresh");

        // Save, then load_or_detect should return saved
        service.save_phases(&result).await.unwrap();
        let loaded = service
            .load_or_detect_phases(vec![EntityType::Character], Some(2), None)
            .await
            .unwrap();
        assert_eq!(loaded.phases.len(), 2);
        // Loaded phases have total_entities=0 (not stored)
        assert_eq!(loaded.total_entities, 0);
    }

    #[tokio::test]
    async fn test_delete_all_phases() {
        let provider = MockTemporalDataProvider::new(
            vec![
                make_entity("a", "A", vec![1.0, 0.0, 0.0, 0.0], vec![0.0], vec![0]),
                make_entity("b", "B", vec![0.0, 1.0, 0.0, 0.0], vec![0.5], vec![50]),
                make_entity("c", "C", vec![0.0, 0.0, 0.0, 1.0], vec![1.0], vec![100]),
            ],
            3,
            vec![],
        );

        let service = TemporalService::with_provider(Arc::new(provider));

        // Detect, save, verify
        let result = service
            .detect_phases(vec![EntityType::Character], Some(2), None)
            .await
            .unwrap();
        service.save_phases(&result).await.unwrap();
        assert!(service.has_saved_phases().await.unwrap());

        // Delete, verify gone
        let deleted = service.delete_all_phases().await.unwrap();
        assert_eq!(deleted, 2);
        assert!(!service.has_saved_phases().await.unwrap());

        // Load should return None
        let loaded = service.load_phases().await.unwrap();
        assert!(loaded.is_none());
    }
}
